# -*- coding: utf-8 -*-
"""Code for Disney & Fox Merger (Substitution Effect).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pCKfcZixiXAsyMcPH1NaUA58u2zSS8UL
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

# Paths
project_path = 'Enter your path'
data_path = project_path+'/data/'

import pandas as pd
import statsmodels.api as sm
import numpy as np
import itertools
import ast
import re
pip install stargazer

# define the list for all disney film studios and fox's film studios
disney_studios = ['20th Century Studios', 'Buena Vista Home Entertainment', 'Buena Vista International',\
 'Buena Vista International Film Production (Germany)',\
 'Buena Vista International Film Production France', 'Buena Vista Negative Cutting',\
 'Buena Vista Pictures', 'Disney Channel', 'Disney Television Animation', 'Disney Theatrical Productions (DTP)',\
 'Disneynature', 'Disneytoon Studios', 'Hollywood Pictures', 'Lucasfilm', 'Lucasfilm Animation', 'Marvel Enterprises',\
 'Marvel Entertainment', 'Marvel Entertainment Group', 'Marvel Knights', 'Marvel Productions', 'Marvel Studios',\
 'Off Hollywood Pictures', 'Pixar Animation Studios', 'The Walt Disney Company', 'Touchstone Films', 'Touchstone Pictures',\
 'Walt Disney Animation Canada', 'Walt Disney Animation France S.A.', 'Walt Disney Animation Japan', 'Walt Disney Animation Studios',\
 'Walt Disney British Films', 'Walt Disney Family Foundation', 'Walt Disney Feature Animation',\
 'Walt Disney Feature Animation Florida', 'Walt Disney Feature Animation Paris', 'Walt Disney Pictures',\
 'Walt Disney Productions', 'Walt Disney Studios', 'Walt Disney Studios Motion Pictures']


fox_studios = ['20th Century Fox', '20th Century Fox Argentina', '20th Century Fox Home Entertainment',\
               '20th Century Fox Television', 'Blue Sky Studios', 'Fox 2000 Pictures', 'Fox Animation Studios',\
               'Fox Atomic', 'Fox Searchlight Pictures', 'Twentieth Century Fox', 'Twentieth Century Fox Animation']

other_major_studios = pd.read_csv(data_path+ r"other major studios.csv")
other_major_studios = other_major_studios['Studio'].to_list()

# data source: https://www.kaggle.com/datasets/raedaddala/top-500-600-movies-of-each-year-from-1960-to-2024
movie_box = pd.read_csv(data_path+'final_dataset.csv')
movie_box.columns
b_movie_box = movie_box[['title', 'gross_us_canada',
       'release_date',
       'production_companies', 'awards_content', 'genres']]


# add in released year
b_movie_box['Release Year'] = pd.to_datetime(b_movie_box['release_date']).dt.year.astype(int)


# clean box office, limit to box office in USD
b_movie_box['Currency']= b_movie_box['gross_us_canada'].str[0]
b_movie_box['Currency'].unique()
c_movie_box = b_movie_box[b_movie_box['Currency']=='$']
c_movie_box['Domestic Box Office'] = c_movie_box['gross_us_canada'].str.replace(',', '').str.replace('$', '').astype(float)


# assign disney/fox dummy variable
c_movie_box['Produced by Disney'] = np.where(c_movie_box['production_companies'].str.contains('|'.join(disney_studios),\
                                                                                              na=False), 1, 0)

c_movie_box['Produced by Fox'] = np.where(c_movie_box['production_companies'].str.contains('|'.join(fox_studios),\
                                                                                              na=False), 1, 0)

c_movie_box['Produced by Warner Bros, Sony, Universal, or Paramount'] = np.where(c_movie_box['production_companies'].str.contains('|'.join(other_major_studios),\
                                                                                              na=False), 1, 0)


# c_movie_box[c_movie_box['Produced by Fox'] ==1]['production_companies'].unique()


# assign award dummy
c_movie_box['Award Winning Movie'] = np.where(c_movie_box['awards_content'].notna(),\
                                              1,\
                                              0)

# assign genre control (use the first genre listed)
c_movie_box['Genre'] = c_movie_box['genres'].str.replace("[", "").str.replace("]", "")
c_movie_box['Genre'] = c_movie_box['Genre'].str.replace("'", "")
c_movie_box['Genre'] = c_movie_box['Genre'].str.split(",").str[0].str.strip()

# reassign box office based on released date and the box office decay
# source of decay: p130 (https://web.stanford.edu/~leinav/pubs/RAND2007.pdf)
box_office_decay_wk = [0, 0.378, 0.607, 0.736, 0.806, 0.856, 0.896, 0.925, 0.950, 0.970, 0.985, 1.000]

box_office_decay_wk_df = pd.DataFrame({"Weeks before Year End": list(np.arange(0, 12, 1)),\
                                       "Share of Tickets Sold in the Year": box_office_decay_wk})
# number of weeks between the release date and the end of the year
c_movie_box["Last Day of Each Year"] = pd.to_datetime(pd.to_datetime(c_movie_box['release_date']).dt.year.astype(str) + "-12-31")
c_movie_box["Weeks before Year End"] = (((c_movie_box["Last Day of Each Year"] -\
                                        pd.to_datetime(c_movie_box['release_date'])).dt.days + 1)//7).astype(int)
c_movie_box["Partial Week before Year End"] = (((c_movie_box["Last Day of Each Year"] -\
                                        pd.to_datetime(c_movie_box['release_date'])).dt.days + 1) %7).astype(int)

d_movie_box = c_movie_box.merge(box_office_decay_wk_df, on="Weeks before Year End", how="left")

d_movie_box["Share of Tickets Sold in the Year"] = np.where((d_movie_box["Share of Tickets Sold in the Year"].isna()),
                                                            1, d_movie_box["Share of Tickets Sold in the Year"])
d_movie_box["Partial Week before Year End"] = np.where(d_movie_box["Share of Tickets Sold in the Year"]==1,\
                                                       0, d_movie_box["Partial Week before Year End"])

d_movie_box["Weeks before Year End_partial"] = d_movie_box["Weeks before Year End"]+1

d_movie_box = d_movie_box.merge(box_office_decay_wk_df.rename(columns = {"Weeks before Year End":"Weeks before Year End_partial",\
                                                                         "Share of Tickets Sold in the Year":\
                                                                         "Share of Tickets Sold in the Partial Week"}),\
                                on="Weeks before Year End_partial", how="left")

d_movie_box["Incremental Share of Tickets Sold in the Partial Week"] = np.where((d_movie_box["Share of Tickets Sold in the Partial Week"].isna()),
                                                            1, d_movie_box["Share of Tickets Sold in the Partial Week"]-\
                                                                    d_movie_box["Share of Tickets Sold in the Year"])

d_movie_box["Domestic Box Office in Release Year"] = d_movie_box["Domestic Box Office"] * d_movie_box["Share of Tickets Sold in the Year"] +\
  d_movie_box["Domestic Box Office"] * d_movie_box["Incremental Share of Tickets Sold in the Partial Week"]* (d_movie_box["Partial Week before Year End"]/7)

d_movie_box["Domestic Box Office in Next Year"] = d_movie_box["Domestic Box Office"]-d_movie_box["Domestic Box Office in Release Year"]
d_movie_box.columns
d_movie_box_m = d_movie_box.melt(
    id_vars=['title', 'gross_us_canada', 'production_companies', 'release_date',
       'awards_content', 'genres', 'Release Year',
        'Produced by Disney', 'Produced by Fox','Produced by Warner Bros, Sony, Universal, or Paramount',
       'Award Winning Movie', 'Genre'],   # keep identifier columns
    value_vars=[
        "Domestic Box Office in Release Year",
        "Domestic Box Office in Next Year"],
    var_name="Year_Type",
    value_name="Box Office"
)

d_movie_box_m['Year'] = np.where(d_movie_box_m["Year_Type"]=="Domestic Box Office in Next Year",\
                                 d_movie_box_m['Release Year'] + 1,\
                                  d_movie_box_m['Release Year'])

# print(d_movie_box_m[d_movie_box_m['Box Office']==0])
d_movie_box_m = d_movie_box_m[['title', 'production_companies',
       'Produced by Disney',
       'Produced by Fox', 'Produced by Warner Bros, Sony, Universal, or Paramount', 'Award Winning Movie', 'Genre',
       'Box Office', 'Year']].rename(columns = {'Box Office':'Domestic Box Office'})

d_movie_box_m['Estimated Box Office Across Movies'] =  d_movie_box_m.groupby('Year')['Domestic Box Office'].transform('sum')
d_movie_box_m = d_movie_box_m[d_movie_box_m['Domestic Box Office']>0]

# total US box office
box = pd.read_excel(data_path+'writing sample data - Movie Industry Price Elasticity Estimate.xlsx', sheet_name='combined')
box = box.iloc[1:,]
box = box[['Year', 'Tickets Sold', 'Total Box Office','Average']].rename(columns = {'Average':'Average Ticket Price'})

# sanity check that annual box office is greater than the box office summed across all movies in the data
# use the price instead
d_movie_box_m_yr =  d_movie_box_m.groupby('Year').agg({'Domestic Box Office':'sum'}).reset_index()
d_movie_box_m_yr_ck = d_movie_box_m_yr.merge(box, on='Year', how='inner')
d_movie_box_m_yr_ck['Greater Total?'] = d_movie_box_m_yr_ck['Total Box Office'] >= d_movie_box_m_yr_ck['Domestic Box Office']
d_movie_box_m_yr_false = d_movie_box_m_yr_ck[d_movie_box_m_yr_ck['Greater Total?']==False]
d_movie_box_m_yr_false['% greater'] = d_movie_box_m_yr_false['Total Box Office']/d_movie_box_m_yr_false['Domestic Box Office']-1
d_movie_box_m_yr_false['% greater'] .mean()

# total US population
pop = pd.read_csv(data_path+'US Population.csv').rename(columns={"POPTOTUSA647NWDB":'Total US Population'})
pop['Year'] = pd.to_datetime(pop['observation_date']).dt.year.astype(int)

# total Canadian population
can_pop = pd.read_excel(data_path+'Canada Population.xlsx').rename(columns={'Canada': 'Total Canada Population'})
pop=pop.merge(can_pop, on='Year', how='outer')
pop = pop[['Year', 'Total US Population', 'Total Canada Population']]
pop['Total Population'] = pop['Total US Population'].fillna(0) + pop['Total Canada Population'].fillna(0)

# find the yearly market size

mkt_size = box.merge(pop, on='Year', how='left')

# conservative market size: assuming everyone has as many annual “movie slots” as the heaviest moviegoing cohort: i.e., 6.5 times per year
# https://www.motionpictures.org/wp-content/uploads/2018/03/MPAA-Theatrical-Market-Statistics-2016_Final-1.pdf?utm_source=chatgpt.com

mkt_size['Movie Choices per Year (Lower Bound)'] = 6.5
mkt_size['Movie Choices per Year (Upper Bound)'] = 12 #if people can choose whether to watch a movie every month

mkt_size['Market Size (Lower Bound)'] = mkt_size['Movie Choices per Year (Lower Bound)']*mkt_size['Total Population']
mkt_size['Market Size (Upper Bound)'] = mkt_size['Movie Choices per Year (Upper Bound)']*mkt_size['Total Population']

b_mkt_size = mkt_size[['Year', 'Tickets Sold', 'Total Box Office', 'Average Ticket Price',\
                       'Market Size (Lower Bound)', 'Market Size (Upper Bound)']]

e_movie_box_m = d_movie_box_m.merge(b_mkt_size, on='Year', how='inner')

e_movie_box_m['Total Box Office_Scaled'] = e_movie_box_m[['Total Box Office',\
                                                          'Estimated Box Office Across Movies']].max(axis=1)
e_movie_box_m['Tickets Sold Per Film'] = e_movie_box_m['Domestic Box Office']/e_movie_box_m['Average Ticket Price']
e_movie_box_m['Mkt Share per Movie (Lower Bound)'] = e_movie_box_m['Tickets Sold Per Film']/e_movie_box_m['Market Size (Lower Bound)']
e_movie_box_m['Mkt Share per Movie (Upper Bound)'] = e_movie_box_m['Tickets Sold Per Film']/e_movie_box_m['Market Size (Upper Bound)']

# estimate the remaining other movie share per year
e_movie_box_m.columns
e_movie_box_oth = e_movie_box_m.groupby(['Year', 'Total Box Office_Scaled',\
                                         'Average Ticket Price',\
                                          'Market Size (Lower Bound)',
                                         'Market Size (Upper Bound)']).agg({'Mkt Share per Movie (Lower Bound)':'sum',\
                                                      'Mkt Share per Movie (Upper Bound)':'sum'}).reset_index()

e_movie_box_oth['All Movies Share (Lower Bound)'] = e_movie_box_oth['Total Box Office_Scaled']/ e_movie_box_oth['Average Ticket Price']
e_movie_box_oth['All Movies Share (Lower Bound)'] = e_movie_box_oth['All Movies Share (Lower Bound)']/ e_movie_box_oth['Market Size (Lower Bound)']
e_movie_box_oth['All Movies Share (Upper Bound)'] = e_movie_box_oth['Total Box Office_Scaled']/ e_movie_box_oth['Average Ticket Price']
e_movie_box_oth['All Movies Share (Upper Bound)'] = e_movie_box_oth['All Movies Share (Upper Bound)']/ e_movie_box_oth['Market Size (Upper Bound)']

e_movie_box_oth['Other Movie Share (Lower Bound)'] = e_movie_box_oth['All Movies Share (Lower Bound)'] -\
                                                            e_movie_box_oth['Mkt Share per Movie (Lower Bound)']

e_movie_box_oth['Other Movie Share (Upper Bound)'] = e_movie_box_oth['All Movies Share (Upper Bound)'] -\
                                                            e_movie_box_oth['Mkt Share per Movie (Upper Bound)']

e_movie_box_oth_low = e_movie_box_oth\
                      .drop(columns=["Mkt Share per Movie (Lower Bound)"], axis=1).melt(id_vars ='Year',\
                                         value_vars = 'Other Movie Share (Lower Bound)',\
                                         var_name = 'title',\
                                         value_name = 'Mkt Share per Movie (Lower Bound)')

e_movie_box_oth_low.loc[e_movie_box_oth_low['Mkt Share per Movie (Lower Bound)']<0, 'Mkt Share per Movie (Lower Bound)'] = 0

e_movie_box_oth_up = e_movie_box_oth\
                      .drop(columns=["Mkt Share per Movie (Upper Bound)"], axis=1).melt(id_vars = 'Year',\
                                         value_vars = 'Other Movie Share (Upper Bound)',\
                                         var_name = 'title',\
                                         value_name = 'Mkt Share per Movie (Upper Bound)')

e_movie_box_oth_up.loc[e_movie_box_oth_up['Mkt Share per Movie (Upper Bound)']<0, 'Mkt Share per Movie (Upper Bound)'] = 0

# construct nested shares within the genre
# cleaning up genre
genre_map = pd.read_csv(data_path+ r"full_genre_mapping.csv").rename(columns = {"original_genre":"Genre",
                                                                                "top_category":"Movie Genre"})
genre_map = genre_map[["Genre", "Movie Genre"]]

e_movie_box_m = e_movie_box_m.merge(genre_map, on = "Genre", how="left")

e_movie_box_m = e_movie_box_m[[ 'Year', 'title', 'production_companies', 'Produced by Disney',
       'Produced by Fox','Produced by Warner Bros, Sony, Universal, or Paramount', 'Award Winning Movie', 'Genre', "Movie Genre",
      'Average Ticket Price',
       'Mkt Share per Movie (Lower Bound)',
       'Mkt Share per Movie (Upper Bound)']]

f_movie_box_m = pd.concat([e_movie_box_m, e_movie_box_oth_low, e_movie_box_oth_up])
f_movie_box_m ['Outside Option Share (Lower Bound)'] = f_movie_box_m.groupby(['Year'])['Mkt Share per Movie (Lower Bound)'].transform('sum')
f_movie_box_m ['Outside Option Share (Lower Bound)'] = 1 - f_movie_box_m ['Outside Option Share (Lower Bound)']
f_movie_box_m ['Outside Option Share (Upper Bound)'] = f_movie_box_m.groupby(['Year'])['Mkt Share per Movie (Upper Bound)'].transform('sum')
f_movie_box_m ['Outside Option Share (Upper Bound)'] = 1 - f_movie_box_m ['Outside Option Share (Upper Bound)']

f_movie_box_m ['Mkt Share per Genre (Lower Bound)'] = f_movie_box_m.groupby(['Year', "Movie Genre"])['Mkt Share per Movie (Lower Bound)'].transform('sum')
f_movie_box_m ['Mkt Share per Genre (Upper Bound)'] = f_movie_box_m.groupby(['Year', "Movie Genre"])['Mkt Share per Movie (Upper Bound)'].transform('sum')

# add in a few controls
# cpi for internet
cpi_internet = pd.read_csv(data_path+ 'CPI for Internet Services.csv')
cpi_internet_q = cpi_internet.copy()
cpi_internet['Year'] = pd.to_datetime(cpi_internet['Label']).dt.strftime('%Y').astype(int)
cpi_internet = cpi_internet[['Year', 'Value']].rename(columns={'Value':'CPI for Internet Services'})
b_cpi_internet = cpi_internet.groupby(['Year'])['CPI for Internet Services'].mean().reset_index()

# internet user
internet_usage = pd.read_csv(data_path+'ITNETUSERP2USA.csv', encoding='latin-1')
internet_usage['Year'] = pd.to_datetime(internet_usage['observation_date']).dt.strftime('%Y')
internet_usage['Year'] = internet_usage['Year'].astype(int)
internet_usage = internet_usage[['Year', 'ITNETUSERP2USA']].rename(columns={'ITNETUSERP2USA':'Internet Users (per 100 People)'})

# netflix's original movie
netflix_og = pd.read_csv(data_path+'NetflixOriginals.csv', encoding='latin-1')
netflix_og["Year"] = netflix_og["Premiere"].str.replace(".", ",", regex=False)
netflix_og["Year"] = netflix_og["Year"].str.split(",").str[-1].str.strip().astype(int)
b_netflix_og = netflix_og.groupby('Year').size().reset_index(name='Number of Netflix OG Movies')

# hulu subscriber
hulu_subscriber =  pd.read_csv(data_path+'archive (1)/Hulu/NumSubscribers.csv', encoding='latin-1').\
        rename(columns={"Subscribers":"Hulu Subscribers (in Millions)"})

# cpi for movie, theatre, and concerts
cpi = pd.read_csv(data_path+'CUUR0000SS62031.csv')
cpi['Year'] = pd.to_datetime(cpi['observation_date']).dt.strftime('%Y').astype(int)
b_cpi = cpi.groupby('Year', dropna=False)['CUUR0000SS62031'].mean().reset_index()
b_cpi = b_cpi.rename(columns={'CUUR0000SS62031':'CPI for Movie, Theaters, and Concerts'})

#number of movie releases
mov = pd.read_excel(data_path+'statistic_id187122_movie-releases-in-the-us-canada-2000-2024.xlsx',\
                        sheet_name='Data', skiprows=4, usecols = "B:C")

mov.columns = ['Year', 'Number of Theatre Movies']

#number of netflix subscriber by the end of each year's quarter
netflix = pd.read_excel(data_path+'Domestic Disney Plus and Netflix Subscriber.xlsx',\
                        sheet_name='Sheet1')
netflix = netflix[['Year', 'Netflix Subscribers (in millions)', 'Disney Plus Subscriber (in millions)']]

g_movie_box_m = f_movie_box_m.merge(b_cpi_internet, on='Year', how='left').merge(internet_usage, on='Year', how='left').merge(netflix, on='Year', how='left').\
merge(b_netflix_og, on='Year', how='left').merge(hulu_subscriber, on='Year', how='left').merge(b_cpi, on='Year', how='left').merge(mov, on='Year', how='left')

# add an interaction term

g_movie_box_m["Pandemic"] = ((g_movie_box_m["Year"]>=2020)).astype(int)

g_movie_box_m["Disney_or_Fox"] = ((g_movie_box_m["Produced by Disney"]==1) |
                             (g_movie_box_m["Produced by Fox"]==1)).astype(int)

g_movie_box_m["PostMerger"] = (g_movie_box_m["Year"] >= 2019).astype(int)

# Interaction: Disney-or-Fox × Post
g_movie_box_m["Disney&Fox_Post"] = g_movie_box_m["Disney_or_Fox"] * g_movie_box_m["PostMerger"]

# Interaction: Netflix X  Disney-or-Fox
g_movie_box_m["Disney&Fox_Netflix_PostMerger"] = g_movie_box_m["Disney_or_Fox"] * g_movie_box_m["Netflix Subscribers (in millions)"]* g_movie_box_m["PostMerger"]
g_movie_box_m["Disney&Fox_Hulu_PostMerger"] = g_movie_box_m["Disney_or_Fox"] * g_movie_box_m["Hulu Subscribers (in Millions)"]* g_movie_box_m["PostMerger"]
g_movie_box_m["Disney&Fox_Disney+_PostMerger"] = g_movie_box_m["Disney_or_Fox"] * g_movie_box_m["Disney Plus Subscriber (in millions)"]* g_movie_box_m["PostMerger"]

# Interaction: Netflix X  Other
g_movie_box_m["Other Major_Netflix_PostMerger"] = g_movie_box_m['Produced by Warner Bros, Sony, Universal, or Paramount'] * g_movie_box_m["Netflix Subscribers (in millions)"]* g_movie_box_m["PostMerger"]
g_movie_box_m["Other Major_Hulu_PostMerger"] = g_movie_box_m['Produced by Warner Bros, Sony, Universal, or Paramount'] * g_movie_box_m["Hulu Subscribers (in Millions)"]* g_movie_box_m["PostMerger"]
g_movie_box_m["Other Major_Disney+_PostMerger"] = g_movie_box_m['Produced by Warner Bros, Sony, Universal, or Paramount'] * g_movie_box_m["Disney Plus Subscriber (in millions)"]* g_movie_box_m["PostMerger"]

# Interaction: Netflix X  Disney-or-Fox X Pandemic
g_movie_box_m["Disney&Fox_Netflix_Pandemic"] = g_movie_box_m["Disney_or_Fox"] * g_movie_box_m["Netflix Subscribers (in millions)"]* g_movie_box_m["PostMerger"] * g_movie_box_m["Pandemic"]
g_movie_box_m["Disney&Fox_Hulu_Pandemic"] = g_movie_box_m["Disney_or_Fox"] * g_movie_box_m["Hulu Subscribers (in Millions)"]* g_movie_box_m["PostMerger"] * g_movie_box_m["Pandemic"]
g_movie_box_m["Disney&Fox_Disney+_Pandemic"] = g_movie_box_m["Disney_or_Fox"] * g_movie_box_m["Disney Plus Subscriber (in millions)"]* g_movie_box_m["PostMerger"] * g_movie_box_m["Pandemic"]
# Interaction: Netflix X  Other X Pandemic
g_movie_box_m["Other Major_Netflix_Pandemic"] = g_movie_box_m['Produced by Warner Bros, Sony, Universal, or Paramount'] * g_movie_box_m["Netflix Subscribers (in millions)"] * g_movie_box_m["Pandemic"]
g_movie_box_m["Other Major_Hulu_Pandemic"] = g_movie_box_m['Produced by Warner Bros, Sony, Universal, or Paramount'] * g_movie_box_m["Hulu Subscribers (in Millions)"]* g_movie_box_m["Pandemic"]
g_movie_box_m["Other Major_Disney+_Pandemic"] = g_movie_box_m['Produced by Warner Bros, Sony, Universal, or Paramount'] * g_movie_box_m["Disney Plus Subscriber (in millions)"]* g_movie_box_m["Pandemic"]

g_movie_box_m['Number of Netflix OG Movies'] = g_movie_box_m['Number of Netflix OG Movies'].fillna(0)
g_movie_box_m = g_movie_box_m[(g_movie_box_m['Year']>=2000) & (g_movie_box_m['Year']<=2024)]
g_movie_box_m = g_movie_box_m[~(g_movie_box_m['title'].isin(['Other Movie Share (Upper Bound)', 'Other Movie Share (Lower Bound)']))]

# export the clean data
g_movie_box_m.to_csv(data_path+r'demand estimation dataset (KS).csv', index=False)

"""# Model Estimation

# Nested Logit with Cleaned Genre
"""

data = pd.read_csv(data_path+r'demand estimation dataset (KS).csv')

data.columns

data["ln(s_jt) - ln(s_0) Lower Bound"] = np.log(data["Mkt Share per Movie (Lower Bound)"]) - np.log(data['Outside Option Share (Lower Bound)'])
data["ln(s_jt) - ln(s_0) Upper Bound"] = np.log(data["Mkt Share per Movie (Upper Bound)"]) - np.log(data['Outside Option Share (Upper Bound)'])
data["ln(s_gt) Lower Bound"] = np.log(data['Mkt Share per Genre (Lower Bound)'])
data["ln(s_gt) Upper Bound"] = np.log(data['Mkt Share per Genre (Upper Bound)'])

# brand-wise demand with year fixed effect
model1 = {}
for share_col in ["ln(s_jt) - ln(s_0) Lower Bound", "ln(s_jt) - ln(s_0) Upper Bound"]:
  print(share_col)
  if "Lower Bound" in share_col:
    data['ln(s_gt)'] = data["ln(s_gt) Lower Bound"]
  else:
    data['ln(s_gt)'] = data["ln(s_gt) Upper Bound"]

  year_col = "Year"

  # add in controls
  X_parts = []

  # data = data[(data['Year']>=2000) & (data['Year']<=2024)]

  for col in ['ln(s_gt)', 'Produced by Disney',
       'Produced by Fox',
       'Produced by Warner Bros, Sony, Universal, or Paramount',
       'Award Winning Movie', 'Disney&Fox_Post']:
      if col in data.columns:
          X_parts.append(data [col].astype(float))

    # Constant
  X_parts.append(pd.DataFrame({"const": np.ones(len(data ))}, index=data .index))

  # categorize genre_dum
  genre_dum = pd.get_dummies(data['Movie Genre'], prefix="genre", drop_first=True).astype(int)
  X_parts.append(genre_dum)

  # Year fixed effects
  year_dum = pd.get_dummies(data[year_col].astype(int), prefix="year", drop_first=True).astype(int)
  X_parts.append(year_dum)

  # create cluster groups
  data["studio"] = "Other"
  data.loc[data["Produced by Disney"] == 1, "studio"] = "Disney"
  data.loc[data["Produced by Fox"] == 1, "studio"] = "Fox"
  data["studio_year"] = data["studio"].astype(str) + "_" + data["Year"].astype(str)
  groups = data["studio_year"]

  # Combine all into one design matrix
  X = pd.concat(X_parts, axis=1)
  y = data [share_col].astype(float)

  mask = y.notna() & (~X.isna().any(axis=1))   # drop any rows with missing
  y = y.loc[mask]
  X = X.loc[mask]
  groups = groups.loc[mask]

  # estimate the model
  res = sm.OLS(y, X).fit(cov_type="cluster", cov_kwds={"groups": groups})
  se_note = "Cluster-robust SEs by Year"

  print(res.summary())

  model1[share_col] = res

# brand-wise demand +substitution with year fixed effect
model2={}
for share_col in ["ln(s_jt) - ln(s_0) Lower Bound", "ln(s_jt) - ln(s_0) Upper Bound"]:
  print(share_col)
  if "Lower Bound" in share_col:
    data['ln(s_gt)'] = data["ln(s_gt) Lower Bound"]
  else:
    data['ln(s_gt)'] = data["ln(s_gt) Upper Bound"]

  year_col = "Year"

  # add in controls
  X_parts = []

  # data = data[(data['Year']>=2000) & (data['Year']<=2024)]

  for col in ['ln(s_gt)','Produced by Disney',
       'Produced by Fox',
       'Produced by Warner Bros, Sony, Universal, or Paramount',
       'Award Winning Movie', 'Disney&Fox_Post', 'Number of Theatre Movies',
        'Number of Netflix OG Movies', 'Netflix Subscribers (in millions)',
       'Disney Plus Subscriber (in millions)',
       'Hulu Subscribers (in Millions)',\
       'Disney&Fox_Netflix_Pandemic', 'Disney&Fox_Hulu_Pandemic',
       'Disney&Fox_Disney+_Pandemic', 'Other Major_Netflix_Pandemic',
       'Other Major_Hulu_Pandemic', 'Other Major_Disney+_Pandemic','Internet Users (per 100 People)']:
      if col in data.columns:
          X_parts.append(data [col].astype(float))

    # Constant
  X_parts.append(pd.DataFrame({"const": np.ones(len(data ))}, index=data .index))

  # categorize genre_dum
  genre_dum = pd.get_dummies(data['Movie Genre'], prefix="genre", drop_first=True).astype(int)
  X_parts.append(genre_dum)

  # Year fixed effects
  year_dum = pd.get_dummies(data[year_col].astype(int), prefix="year", drop_first=True).astype(int)
  X_parts.append(year_dum)

  # create cluster groups
  data["studio"] = "Other"
  data.loc[data["Produced by Disney"] == 1, "studio"] = "Disney"
  data.loc[data["Produced by Fox"] == 1, "studio"] = "Fox"
  data["studio_year"] = data["studio"].astype(str) + "_" + data["Year"].astype(str)
  groups = data["studio_year"]

  # Combine all into one design matrix
  X = pd.concat(X_parts, axis=1)
  y = data [share_col].astype(float)

  mask = y.notna() & (~X.isna().any(axis=1))   # drop any rows with missing
  y = y.loc[mask]
  X = X.loc[mask]
  groups = groups.loc[mask]

  # estimate the model
  res = sm.OLS(y, X).fit(cov_type="cluster", cov_kwds={"groups": groups})
  se_note = "Cluster-robust SEs by Year"

  print(res.summary())

  model2[share_col] = res

# cross year effects
model3={}
for share_col in ["ln(s_jt) - ln(s_0) Lower Bound", "ln(s_jt) - ln(s_0) Upper Bound"]:
  print(share_col)

  if "Lower Bound" in share_col:
    data['ln(s_gt)'] = data["ln(s_gt) Lower Bound"]
  else:
    data['ln(s_gt)'] = data["ln(s_gt) Upper Bound"]

  year_col = "Year"

  # add in controls
  X_parts = []

  # data = data[(data['Year']>=2000) & (data['Year']<=2024)]

  for col in ['ln(s_gt)', 'Produced by Disney',
       'Produced by Fox',
       'Produced by Warner Bros, Sony, Universal, or Paramount',
       'Award Winning Movie', 'Disney&Fox_Post', 'Number of Theatre Movies',
       'Number of Netflix OG Movies', 'Netflix Subscribers (in millions)',
       'Disney Plus Subscriber (in millions)',
       'Hulu Subscribers (in Millions)',\
       'Disney&Fox_Netflix_Pandemic', 'Disney&Fox_Hulu_Pandemic',
       'Disney&Fox_Disney+_Pandemic', 'Other Major_Netflix_Pandemic',
       'Other Major_Hulu_Pandemic', 'Other Major_Disney+_Pandemic',\
      'Internet Users (per 100 People)', 'Pandemic']:
          X_parts.append(data [col].astype(float))

    # Constant
  X_parts.append(pd.DataFrame({"const": np.ones(len(data ))}, index=data .index))

  # categorize genre_dum
  genre_dum = pd.get_dummies(data['Movie Genre'], prefix="genre", drop_first=True).astype(int)
  X_parts.append(genre_dum)

  # create cluster groups
  data["studio"] = "Other"
  data.loc[data["Produced by Disney"] == 1, "studio"] = "Disney"
  data.loc[data["Produced by Fox"] == 1, "studio"] = "Fox"
  data["studio_year"] = data["studio"].astype(str) + "_" + data["Year"].astype(str)
  groups = data["studio_year"]

  # Combine all into one design matrix
  X = pd.concat(X_parts, axis=1)
  y = data [share_col].astype(float)

  mask = y.notna() & (~X.isna().any(axis=1))   # drop any rows with missing
  y = y.loc[mask]
  X = X.loc[mask]
  groups = groups.loc[mask]

  # estimate the model
  res = sm.OLS(y, X).fit(cov_type="cluster", cov_kwds={"groups": groups})
  se_note = "Cluster-robust SEs by Year"

  print(res.summary())

  model3[share_col] = res

from stargazer.stargazer import Stargazer

models = [model1["ln(s_jt) - ln(s_0) Lower Bound"],
          model2["ln(s_jt) - ln(s_0) Lower Bound"],
          model3["ln(s_jt) - ln(s_0) Lower Bound"]]

# 2. Get the list of all variable names from the model
keep_covariates = model3["ln(s_jt) - ln(s_0) Lower Bound"].params.index.tolist()
keep_covariates = [
    cov for cov in keep_covariates
    if not re.match(r'^(year|genre)', cov)
]

stargazer = Stargazer(models)
stargazer.title("Regression Results")
stargazer.custom_columns(["Within-Brand", "Substitutions", "Substitions No FE"], [1, 1, 1])
stargazer.covariate_order(keep_covariates)
stargazer.add_line(
    'Film Genre Fixed Effects', ['Yes', 'Yes', 'Yes'])
stargazer.add_line(
    'Year Fixed Effects', ['Yes', 'Yes', 'No'])
stargazer.omit_dependent_variable = True

stargazer

from stargazer.stargazer import Stargazer

models = [model1["ln(s_jt) - ln(s_0) Upper Bound"],
          model2["ln(s_jt) - ln(s_0) Upper Bound"],
          model3["ln(s_jt) - ln(s_0) Upper Bound"]]

# 2. Get the list of all variable names from the model
keep_covariates = model3["ln(s_jt) - ln(s_0) Upper Bound"].params.index.tolist()
keep_covariates = [
    cov for cov in keep_covariates
    if not re.match(r'^(year|genre)', cov)
]

stargazer = Stargazer(models)
stargazer.title("Regression Results")
stargazer.custom_columns(["Within-Brand", "Substitutions", "Substitions No FE"], [1, 1, 1])
stargazer.covariate_order(keep_covariates)
stargazer.add_line(
    'Film Genre Fixed Effects', ['Yes', 'Yes', 'Yes'])
stargazer.add_line(
    'Year Fixed Effects', ['Yes', 'Yes', 'No'])
stargazer.omit_dependent_variable = True

stargazer

"""# Multinomial Logit Model"""

data = pd.read_csv(data_path+r'demand estimation dataset (KS).csv')

data["ln(s_jt) - ln(s_0) Lower Bound"] = np.log(data["Mkt Share per Movie (Lower Bound)"]) - np.log(data['Outside Option Share (Lower Bound)'])
data["ln(s_jt) - ln(s_0) Upper Bound"] = np.log(data["Mkt Share per Movie (Upper Bound)"]) - np.log(data['Outside Option Share (Upper Bound)'])

# brand-wise demand with year fixed effect
model1 = {}
for share_col in ["ln(s_jt) - ln(s_0) Lower Bound", "ln(s_jt) - ln(s_0) Upper Bound"]:
  print(share_col)
  year_col = "Year"

  # add in controls
  X_parts = []

  for col in [ 'Produced by Disney',
       'Produced by Fox',
       'Produced by Warner Bros, Sony, Universal, or Paramount',
       'Award Winning Movie', 'Disney&Fox_Post']:
      if col in data.columns:
          X_parts.append(data [col].astype(float))

    # Constant
  X_parts.append(pd.DataFrame({"const": np.ones(len(data ))}, index=data .index))

  # categorize genre_dum
  genre_dum = pd.get_dummies(data["Genre"], prefix="genre", drop_first=True).astype(int)
  X_parts.append(genre_dum)

  # Year fixed effects
  year_dum = pd.get_dummies(data[year_col].astype(int), prefix="year", drop_first=True).astype(int)
  X_parts.append(year_dum)

  # create cluster groups
  data["studio"] = "Other"
  data.loc[data["Produced by Disney"] == 1, "studio"] = "Disney"
  data.loc[data["Produced by Fox"] == 1, "studio"] = "Fox"
  data["studio_year"] = data["studio"].astype(str) + "_" + data["Year"].astype(str)
  groups = data["studio_year"]

  # Combine all into one design matrix
  X = pd.concat(X_parts, axis=1)
  y = data [share_col].astype(float)

  mask = y.notna() & (~X.isna().any(axis=1))   # drop any rows with missing
  y = y.loc[mask]
  X = X.loc[mask]
  groups = groups.loc[mask]

  # estimate the model
  res = sm.OLS(y, X).fit(cov_type="cluster", cov_kwds={"groups": groups})
  se_note = "Cluster-robust SEs by Year"

  print(res.summary())

  model1[share_col] = res

# brand-wise demand +substitution with year fixed effect
model2={}
for share_col in ["ln(s_jt) - ln(s_0) Lower Bound", "ln(s_jt) - ln(s_0) Upper Bound"]:
  print(share_col)
  year_col = "Year"

  # add in controls
  X_parts = []

  for col in [ 'Produced by Disney',
       'Produced by Fox',
       'Produced by Warner Bros, Sony, Universal, or Paramount',
       'Award Winning Movie', 'Disney&Fox_Post', 'Number of Theatre Movies',
        'Number of Netflix OG Movies', 'Netflix Subscribers (in millions)',
       'Disney Plus Subscriber (in millions)',
       'Hulu Subscribers (in Millions)',\
       'Disney&Fox_Netflix_Pandemic', 'Disney&Fox_Hulu_Pandemic',
       'Disney&Fox_Disney+_Pandemic', 'Other Major_Netflix_Pandemic',
       'Other Major_Hulu_Pandemic', 'Other Major_Disney+_Pandemic','Internet Users (per 100 People)']:
      if col in data.columns:
          X_parts.append(data [col].astype(float))

    # Constant
  X_parts.append(pd.DataFrame({"const": np.ones(len(data ))}, index=data .index))

  # categorize genre_dum
  genre_dum = pd.get_dummies(data["Genre"], prefix="genre", drop_first=True).astype(int)
  X_parts.append(genre_dum)

  # Year fixed effects
  year_dum = pd.get_dummies(data[year_col].astype(int), prefix="year", drop_first=True).astype(int)
  X_parts.append(year_dum)

  # create cluster groups
  data["studio"] = "Other"
  data.loc[data["Produced by Disney"] == 1, "studio"] = "Disney"
  data.loc[data["Produced by Fox"] == 1, "studio"] = "Fox"
  data["studio_year"] = data["studio"].astype(str) + "_" + data["Year"].astype(str)
  groups = data["studio_year"]

  # Combine all into one design matrix
  X = pd.concat(X_parts, axis=1)
  y = data [share_col].astype(float)

  mask = y.notna() & (~X.isna().any(axis=1))   # drop any rows with missing
  y = y.loc[mask]
  X = X.loc[mask]
  groups = groups.loc[mask]

  # estimate the model
  res = sm.OLS(y, X).fit(cov_type="cluster", cov_kwds={"groups": groups})
  se_note = "Cluster-robust SEs by Year"

  print(res.summary())

  model2[share_col] = res

# cross year effects
model3={}
for share_col in ["ln(s_jt) - ln(s_0) Lower Bound", "ln(s_jt) - ln(s_0) Upper Bound"]:
  print(share_col)
  year_col = "Year"

  # add in controls
  X_parts = []

  for col in [ 'Produced by Disney',
       'Produced by Fox',
       'Produced by Warner Bros, Sony, Universal, or Paramount',
       'Award Winning Movie', 'Disney&Fox_Post', 'Number of Theatre Movies',
       'Number of Netflix OG Movies', 'Netflix Subscribers (in millions)',
       'Disney Plus Subscriber (in millions)',
       'Hulu Subscribers (in Millions)',\
       'Disney&Fox_Netflix_Pandemic', 'Disney&Fox_Hulu_Pandemic',
       'Disney&Fox_Disney+_Pandemic', 'Other Major_Netflix_Pandemic',
       'Other Major_Hulu_Pandemic', 'Other Major_Disney+_Pandemic',\
      'Internet Users (per 100 People)', 'Pandemic']:
          X_parts.append(data [col].astype(float))

    # Constant
  X_parts.append(pd.DataFrame({"const": np.ones(len(data ))}, index=data .index))

  # categorize genre_dum
  genre_dum = pd.get_dummies(data["Genre"], prefix="genre", drop_first=True).astype(int)
  X_parts.append(genre_dum)

  # create cluster groups
  data["studio"] = "Other"
  data.loc[data["Produced by Disney"] == 1, "studio"] = "Disney"
  data.loc[data["Produced by Fox"] == 1, "studio"] = "Fox"
  data["studio_year"] = data["studio"].astype(str) + "_" + data["Year"].astype(str)
  groups = data["studio_year"]

  # Combine all into one design matrix
  X = pd.concat(X_parts, axis=1)
  y = data [share_col].astype(float)

  mask = y.notna() & (~X.isna().any(axis=1))   # drop any rows with missing
  y = y.loc[mask]
  X = X.loc[mask]
  groups = groups.loc[mask]

  # estimate the model
  res = sm.OLS(y, X).fit(cov_type="cluster", cov_kwds={"groups": groups})
  se_note = "Cluster-robust SEs by Year"

  print(res.summary())

  model3[share_col] = res

from stargazer.stargazer import Stargazer

models = [model1["ln(s_jt) - ln(s_0) Lower Bound"],
          model2["ln(s_jt) - ln(s_0) Lower Bound"],
          model3["ln(s_jt) - ln(s_0) Lower Bound"]]

# 2. Get the list of all variable names from the model
keep_covariates = model3["ln(s_jt) - ln(s_0) Lower Bound"].params.index.tolist()
keep_covariates = [
    cov for cov in keep_covariates
    if not re.match(r'^(year|genre)', cov)
]

stargazer = Stargazer(models)
stargazer.title("Regression Results")
stargazer.custom_columns(["Within-Brand", "Substitutions", "Substitions No FE"], [1, 1, 1])
stargazer.covariate_order(keep_covariates)
stargazer.add_line(
    'Film Genre Fixed Effects', ['Yes', 'Yes', 'Yes'])
stargazer.add_line(
    'Year Fixed Effects', ['Yes', 'Yes', 'No'])
stargazer.omit_dependent_variable = True

stargazer

from stargazer.stargazer import Stargazer

models = [model1["ln(s_jt) - ln(s_0) Upper Bound"],
          model2["ln(s_jt) - ln(s_0) Upper Bound"],
          model3["ln(s_jt) - ln(s_0) Upper Bound"]]

# 2. Get the list of all variable names from the model
keep_covariates = model3["ln(s_jt) - ln(s_0) Lower Bound"].params.index.tolist()
keep_covariates = [
    cov for cov in keep_covariates
    if not re.match(r'^(year|genre)', cov)
]

stargazer = Stargazer(models)
stargazer.title("Regression Results")
stargazer.custom_columns(["Within-Brand", "Substitutions", "Substitions No FE"], [1, 1, 1])
stargazer.covariate_order(keep_covariates)
stargazer.add_line(
    'Film Genre Fixed Effects', ['Yes', 'Yes', 'Yes'])
stargazer.add_line(
    'Year Fixed Effects', ['Yes', 'Yes', 'No'])
stargazer.omit_dependent_variable = True

stargazer